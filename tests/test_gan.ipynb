{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:04:24.235009120Z",
     "start_time": "2023-09-18T14:04:23.477325432Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from __datasets__ import ITSDataset, DenseHazeCVPR2019Dataset, DomainDataset\n",
    "from gan.utils import CycleGANConfig, save_checkpoint, load_checkpoint, display_images\n",
    "from gan.generator import Generator\n",
    "from gan.discriminator import Discriminator\n",
    "from gan.trainer import PerceptualLoss, train, get_cycle_gan_trainer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:04:26.959235419Z",
     "start_time": "2023-09-18T14:04:24.236772906Z"
    }
   },
   "id": "956acd0c946e9181"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "config1 = CycleGANConfig(\n",
    "    \"../../commons/datasets/its/\",\n",
    "    \"HazeGan\",\n",
    "    \"v1\",\n",
    "    image_shape=(3, 64, 64),\n",
    "    latent_dim=64,\n",
    "    epochs=1, batch_size=8,\n",
    "    lr=2e-4,\n",
    "    betas=(0.5, 0.999),\n",
    "    lambdas=(10, 0.5),\n",
    "    residuals=5,\n",
    "    blocks=(64, 128, 256, 512)\n",
    ")\n",
    "config2 = CycleGANConfig(\n",
    "    \"../../commons/datasets/dense_haze_cvpr2019/\",\n",
    "    \"HazeGan\",\n",
    "    \"v1\",\n",
    "    image_shape=(3, 128, 128),\n",
    "    latent_dim=64,\n",
    "    epochs=1, batch_size=8,\n",
    "    lr=2e-4,\n",
    "    betas=(0.5, 0.999),\n",
    "    lambdas=(10, 0.5),\n",
    "    residuals=5,\n",
    "    blocks=(64, 128, 256, 512)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:13:03.582945933Z",
     "start_time": "2023-09-18T14:13:03.519738279Z"
    }
   },
   "id": "3360d2818ce85e56"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(2798, 55)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = DomainDataset(\n",
    "    ITSDataset(config1.dataset_path, SET=\"hazy\", download=True, img_transform=config1.transforms, sub_sample=0.2),\n",
    "    ITSDataset(config1.dataset_path, SET=\"clear\", download=True, img_transform=config1.transforms, sub_sample=1)\n",
    ").to(config1.device)\n",
    "ds2 = DomainDataset(\n",
    "    DenseHazeCVPR2019Dataset(config2.dataset_path, SET=\"hazy\", download=True, img_transform=config2.transforms, sub_sample=1),\n",
    "    DenseHazeCVPR2019Dataset(config2.dataset_path, SET=\"GT\", download=True, img_transform=config2.transforms, sub_sample=1)\n",
    ").to(config1.device)\n",
    "len(ds1), len(ds2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:13:04.366342701Z",
     "start_time": "2023-09-18T14:13:04.150298991Z"
    }
   },
   "id": "b255bf8e9f03f347"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "generatorA = Generator(config1.image_shape[0], config1.latent_dim, config1.residuals).to(config1.device)\n",
    "generatorB = Generator(config1.image_shape[0], config1.latent_dim, config1.residuals).to(config1.device)\n",
    "discriminatorA = Discriminator(config1.image_shape[0], list(config1.blocks)).to(config1.device)\n",
    "discriminatorB = Discriminator(config1.image_shape[0], list(config1.blocks)).to(config1.device)\n",
    "optimizerG = optim.Adam(\n",
    "    list(generatorA.parameters()) + list(generatorB.parameters()),\n",
    "    lr=config1.lr,\n",
    "    betas=config1.betas\n",
    ")\n",
    "optimizerD = optim.Adam(\n",
    "    list(discriminatorA.parameters()) + list(discriminatorB.parameters()),\n",
    "    lr=config1.lr,\n",
    "    betas=config1.betas\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:13:06.528144591Z",
     "start_time": "2023-09-18T14:13:06.362994976Z"
    }
   },
   "id": "146a7274921d27d1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "perceptual_model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features[:35].to(config1.device)\n",
    "perceptual_loss = PerceptualLoss(perceptual_model)\n",
    "fixedA, fixedB = ds1[:4].values()\n",
    "trainer = get_cycle_gan_trainer(generatorA, generatorB, discriminatorA, discriminatorB, optimizerG, optimizerD,\n",
    "                                perceptual_loss=perceptual_loss, lambda_cycle=config1.lambdas[0],\n",
    "                                lambda_identity=config1.lambdas[1],\n",
    "                                writer=config1.writer, period=100,\n",
    "                                fixedA=fixedA, fixedB=fixedB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:13:11.061504305Z",
     "start_time": "2023-09-18T14:13:08.764135765Z"
    }
   },
   "id": "4284189ab6408161"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "file_path = \".pt\"\n",
    "others = load_checkpoint(\n",
    "    file_path,\n",
    "    {\"generator_A\": generatorA, \"generator_B\": generatorB, \"discriminator_A\": discriminatorA, \"discriminator_B\": discriminatorB},\n",
    "    {\"optimizer_G\": optimizerG, \"optimizer_D\": optimizerD},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:13:11.096012843Z",
     "start_time": "2023-09-18T14:13:11.062387891Z"
    }
   },
   "id": "65ba2288a732c3dc"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch: 0/1 | Batch 0/350|          |  0% [00:00<?, ?it/s, loss=?]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c890aee4e6cf48d3a6d6272c1da81fdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mne\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/gan/trainer.py:33\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(trainer, ds, ne, bs, collate_fn)\u001B[0m\n\u001B[1;32m     31\u001B[0m prog: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTQDM\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m tqdm(dl, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: 0/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mne\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Batch\u001B[39m\u001B[38;5;124m\"\u001B[39m, postfix\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m}, bar_format\u001B[38;5;241m=\u001B[39mBAR_FORMAT)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch, DATA \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(prog):\n\u001B[0;32m---> 33\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdl\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     loss_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     35\u001B[0m     prog\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mne\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Batch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/gan/trainer.py:60\u001B[0m, in \u001B[0;36mget_cycle_gan_trainer.<locals>.trainer\u001B[0;34m(DATA, step)\u001B[0m\n\u001B[1;32m     58\u001B[0m fakeA, fakeB \u001B[38;5;241m=\u001B[39m generatorA(realB), generatorB(realA)\n\u001B[1;32m     59\u001B[0m backA, backB \u001B[38;5;241m=\u001B[39m generatorA(fakeB), generatorB(fakeA)\n\u001B[0;32m---> 60\u001B[0m sameA, sameB \u001B[38;5;241m=\u001B[39m \u001B[43mgeneratorA\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrealA\u001B[49m\u001B[43m)\u001B[49m, generatorB(realB)\n\u001B[1;32m     61\u001B[0m pred_realA, pred_realB \u001B[38;5;241m=\u001B[39m discriminatorA(realA), discriminatorB(realB)\n\u001B[1;32m     62\u001B[0m pred_fakeA_true, pred_fakeB_true \u001B[38;5;241m=\u001B[39m discriminatorA(fakeA\u001B[38;5;241m.\u001B[39mdetach()), discriminatorB(fakeB\u001B[38;5;241m.\u001B[39mdetach())\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/gan/generator.py:77\u001B[0m, in \u001B[0;36mGenerator.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     75\u001B[0m     x \u001B[38;5;241m=\u001B[39m down_block(x)\n\u001B[1;32m     76\u001B[0m     skip_connections\u001B[38;5;241m.\u001B[39mappend(x)\n\u001B[0;32m---> 77\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresidual_blocks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m skip_connection, up_block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mreversed\u001B[39m(skip_connections), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup_blocks):\n\u001B[1;32m     79\u001B[0m     x \u001B[38;5;241m=\u001B[39m up_block(torch\u001B[38;5;241m.\u001B[39mcat([x, skip_connection], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/gan/generator.py:44\u001B[0m, in \u001B[0;36mResidualBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m x\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/hazemaze/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_conv_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 456\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reversed_padding_repeated_twice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_mode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m                        \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    460\u001B[0m                     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    trainer, ds1,\n",
    "    ne=config1.epochs, bs=config1.batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:28:25.817635197Z",
     "start_time": "2023-09-18T14:28:06.882456222Z"
    }
   },
   "id": "ca99c3a43637171f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_checkpoint(\n",
    "    config1.checkpoint_path,\n",
    "    {\"generatorA\": generatorA, \"generatorB\": generatorB, \"discriminatorA\": discriminatorA, \"discriminatorB\": discriminatorB},\n",
    "    {\"optimizerG\": optimizerG, \"optimizerD\": optimizerD},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f536c23dd29cab65"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928 ms ± 45.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "_, fixedB = ds2[:24].values()\n",
    "generatorA = generatorA.eval()\n",
    "with torch.inference_mode():\n",
    "    %timeit generatorA(fixedB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T14:31:42.528556779Z",
     "start_time": "2023-09-18T14:31:34.245275704Z"
    }
   },
   "id": "954830dfaed72fe4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 19.6 s, total: 2min 10s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fixedA, fixedB = ds2[:9].values()\n",
    "with torch.inference_mode():\n",
    "    grid_realA = make_grid(fixedA, nrow=1, normalize=True)\n",
    "    grid_realB = make_grid(fixedB, nrow=1, normalize=True)\n",
    "    grid_fakeA = make_grid(fakeA := generatorA(fixedB), nrow=1, normalize=True)\n",
    "    grid_fakeB = make_grid(fakeB := generatorB(fixedA), nrow=1, normalize=True)\n",
    "    grid_cycleA = make_grid(generatorA(fakeB), nrow=1, normalize=True)\n",
    "    grid_cycleB = make_grid(generatorB(fakeA), nrow=1, normalize=True)\n",
    "    grid_identityA = make_grid(identityA := generatorA(fixedA), nrow=1, normalize=True)\n",
    "    grid_identityB = make_grid(identityB := generatorB(fixedB), nrow=1, normalize=True)\n",
    "    grid_doubleA = make_grid(generatorA(identityB), nrow=1, normalize=True)\n",
    "    grid_doubleB = make_grid(generatorB(identityA), nrow=1, normalize=True)\n",
    "    gridA = make_grid(torch.stack([grid_realA, grid_fakeB, grid_doubleB, grid_cycleA, grid_identityA]), nrow=5, normalize=True)\n",
    "    gridB = make_grid(torch.stack([grid_realB, grid_fakeA, grid_doubleA, grid_cycleB, grid_identityB]), nrow=5, normalize=True)\n",
    "display_images(torch.stack([gridA, gridB]).permute(0, 2, 3, 1).cpu())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T13:56:28.713240605Z",
     "start_time": "2023-09-18T13:55:21.689594923Z"
    }
   },
   "id": "acbbe2e7f2efdd8b"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_image(gridA, \"gridA.png\"), save_image(gridB, \"gridB.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T17:39:55.340269937Z",
     "start_time": "2023-09-17T17:39:49.237536684Z"
    }
   },
   "id": "725e01c882dfe5d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c325dc75843b33b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
